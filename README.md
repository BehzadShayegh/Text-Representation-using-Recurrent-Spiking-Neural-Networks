# Text-Representation-using-Recurrent-Spiking-Neural-Networks
Computational Neuroscience - UT CS - Spring 2021

This project implements a recurrent spiking neural network to produce representations of texts of different lengths, considering the order of words, using STDP. Because of the time limit, I couldn't finish this project, and it has been temporarily suspended.
At the time I was trying to solve this problem, there was not any successful similar work. According to the lack of research in text processing using SNNs, There were not any helpful tools. My main problem was that I had not any word representation for this task. So I had to perform it first. As I was trying to do this unsupervised (STDP), I couldn't be successful.
So the absence of words spiking representations was the main issue. I'll work on both problems (word representations and recurrent SNNs' text representations) as soon as I get some time.
You can see a simple view of the network I was using and the hopeless results I got on the last try.

<div align="center">
    <img src="https://github.com/BehzadShayegh/Text-Representation-using-Recurrent-Spiking-Neural-Networks/blob/master/model.jpg" height="400px"/>
    <br/>
    <img src="https://github.com/BehzadShayegh/Text-Representation-using-Recurrent-Spiking-Neural-Networks/blob/master/result.jpg" height="400px"/>
</div>
